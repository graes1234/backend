from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import os
import sqlite3
from fastapi.responses import FileResponse, StreamingResponse
import json
from model_loader import predict_fabric, load_and_preprocess, run_inference, class_names
import asyncio
import time
from fastapi.staticfiles import StaticFiles

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

app = FastAPI()
os.makedirs("uploads", exist_ok=True)

model_ready = False

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],   # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (Wix/ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# DB ê²½ë¡œ
DB_PATH = "DB/fabrics.db"

DEMO_IMAGE_DIR = os.path.join(BASE_DIR, "image")
os.makedirs(DEMO_IMAGE_DIR, exist_ok=True)

app.mount("/image", StaticFiles(directory=DEMO_IMAGE_DIR), name="demo-images")

# DBì—ì„œ ì„¸íƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def get_fabric_info(fabric_name):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        "SELECT fabric, ko_name, wash_method, dry_method, special_note FROM fabric_care WHERE LOWER(fabric) = LOWER(?)",
        (fabric_name,),
    )
    result = cur.fetchone()
    conn.close()
    return result
    
#ë°©ëª…ë¡ DB
GUESTBOOK_DB = "DB/guestbook.db"

# ë°©ëª…ë¡ DB ì´ˆê¸°í™”
def init_guestbook_db():
    conn = sqlite3.connect(GUESTBOOK_DB)
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS guestbook (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            contactInfo TEXT,
            message TEXT NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    conn.commit()
    conn.close()


@app.get("/ping")
def ping():
    return {"status": "alive"}

@app.get("/")
async def read_root():
    index_path = os.path.join("../front", "index.html")
    if os.path.exists(index_path):
        return FileResponse(index_path)
    return {"message": "Server is running!"}

@app.get("/demo_files")
def get_demo_files():
    demo_dir = os.path.join(BASE_DIR, "image")
    os.makedirs(demo_dir, exist_ok=True)

    files = [
        f for f in os.listdir(demo_dir)
        if f.lower().endswith((".jpg", ".jpeg", ".png"))
    ]

    return {"files": files}

@app.post("/predict_stream")
async def predict_stream(file: UploadFile = File(...), demo: str = Form("0")):
    file_bytes = await file.read()
    filepath = f"uploads/{file.filename}"
    with open(filepath, "wb") as f:
        f.write(file_bytes)
            
    async def event_generator(): #event_stream
        # 1. ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥
        yield json.dumps({"status": "ğŸ“â³ğŸ’¾ ì´ë¯¸ì§€ ì €ì¥ ì¤‘..."}) + "\n"
        if demo == "1":
            await asyncio.sleep(1)

        # 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        yield json.dumps({"status": "ğŸ§¼ğŸ§ªğŸ”§ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘..."}) + "\n"
        x = load_and_preprocess(filepath)
        if demo == "1":
            await asyncio.sleep(1)

        # 3. ì˜ˆì¸¡ ì‹œì‘
        yield json.dumps({"status": "ğŸ”âš¡ğŸ“Šê²°ê³¼ ì˜ˆì¸¡ ì¤‘..."}) + "\n"
        if demo == "1":
            await asyncio.sleep(1)

        #  ì‹¤ì œ ëª¨ë¸ ì˜ˆì¸¡ (ê±¸ë¦¬ëŠ” ì‹œê°„ ê·¸ëŒ€ë¡œ ìŠ¤íŠ¸ë¦¬ë°ì— ë°˜ì˜ë¨)
        preds = run_inference(x)

        # ê²°ê³¼ ìƒìœ„ 3ê°œ ì •ë ¬
        top3 = [
            {"label": class_names[i], "score": float(preds[i])}
            for i in range(len(class_names))
        ]
        top3 = sorted(top3, key=lambda x: x["score"], reverse=True)[:3]

        top_fabric = top3[0]["label"]
        info = get_fabric_info(top_fabric)

        result = {
            "filename": file.filename,
            "predictions": top3,
            "predicted_fabric": top_fabric,
        }

        if info:
            result.update({
                "ko_name": info[1],
                "wash_method": info[2],
                "dry_method": info[3],
                "special_note": info[4]
            })

        yield json.dumps({
            "status": "âœ…ğŸ‰âœ¨ ì˜ˆì¸¡ ì™„ë£Œ!",
            "result": result
        }) + "\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/plain",
        headers={"Cache-Control": "no-cache"}
    )

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # 1. íŒŒì¼ ì €ì¥
        filepath = f"uploads/{file.filename}"
        with open(filepath, "wb") as f:
            f.write(await file.read())

        # 2. ëª¨ë¸ ì¶”ë¡ 
        raw_results = predict_fabric(filepath)
        print("ğŸ”¥ raw_results:", raw_results)

        # 3. ì˜ˆì¸¡ ê²°ê³¼ ì •ì œ (Top3)
        # ì˜ˆ: raw_results = [{"label": "cotton", "score": 0.87}, {"label": "polyester", "score": 0.09}, ...]
        top3 = sorted(raw_results, key=lambda x: x.get("score", 0), reverse=True)[:3]
        predictions = [
            {"label": x["label"], "score": round(float(x["score"]), 4)} for x in top3
        ]

        # 4. Top1ìœ¼ë¡œ DB ì¡°íšŒ
        top_fabric = top3[0]["label"]
        info = get_fabric_info(top_fabric)

        # 5. ê²°ê³¼ ìƒì„±
        response = {
            "filename": file.filename,
            "predictions": predictions,
            "predicted_fabric": top_fabric,
        }

        if info:
            response.update({
                "ko_name": info[1],
                "wash_method": info[2],
                "dry_method": info[3],
                "special_note": info[4]
            })
        else:
            response["error"] = "DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return response

    except Exception as e:
        print("âŒ ì„œë²„ ì˜¤ë¥˜:", e)
        return {"predictions": [], "error": f"ì„œë²„ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {str(e)}"}

@app.get("/fabric_info/{fabric_name}")
def fabric_info(fabric_name: str):
    info = get_fabric_info(fabric_name)
    if not info:
        raise HTTPException(status_code=404, detail="Fabric not found")
    return {
        "fabric": info[0],
        "ko_name": info[1],
        "wash_method": info[2],
        "dry_method": info[3],
        "special_note": info[4]
    }

#ë°©ëª…ë¡ ê´€ë ¨ API
#ê¸€ ì €ì¥
@app.post("/guestbook")
def add_guestbook(data: dict):
    name = data.get("name")
    contact = data.get("contactInfo")
    message = data.get("message")

    conn = sqlite3.connect(GUESTBOOK_DB)
    cur = conn.cursor()
    cur.execute(
        "INSERT INTO guestbook (name, contactInfo, message) VALUES (?, ?, ?)",
        (name, contact, message)
    )
    conn.commit()
    last_id = cur.lastrowid
    conn.close()

    return {"id": last_id, "success": True}

#ì „ì²´ ë¶ˆëŸ¬ì˜¤ê¸°
@app.get("/guestbook")
def get_guestbook():
    conn = sqlite3.connect(GUESTBOOK_DB)
    cur = conn.cursor()
    cur.execute("SELECT id, name, contactInfo, message, created_at FROM guestbook ORDER BY id DESC")
    rows = cur.fetchall()
    conn.close()

    result = []
    for r in rows:
        result.append({
            "id": r[0],
            "name": r[1],
            "contactInfo": r[2],
            "message": r[3],
            "created_at": r[4]
        })
    return result

#ê°œë³„ ì‚­ì œ
@app.delete("/guestbook/{entry_id}")
def delete_guestbook(entry_id: int):
    conn = sqlite3.connect(GUESTBOOK_DB)
    cur = conn.cursor()
    cur.execute("DELETE FROM guestbook WHERE id = ?", (entry_id,))
    conn.commit()
    conn.close()
    return {"success": True}


# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)


