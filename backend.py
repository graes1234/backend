from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import sqlite3
import uvicorn
import os
from model_loader import predict_fabric  # AI ì˜ˆì¸¡ í•¨ìˆ˜

app = FastAPI()
os.makedirs("uploads", exist_ok=True)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (Wix/ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
    allow_methods=["*"],
    allow_headers=["*"],
)

# DB ê²½ë¡œ
DB_PATH = "DB/fabrics.db"

# DBì—ì„œ ì„¸íƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def get_fabric_info(fabric_name):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        """
        SELECT fabric, ko_name, wash_method, dry_method, special_note
        FROM fabric_care
        WHERE LOWER(fabric) = LOWER(?)
        """,
        (fabric_name,),
    )
    result = cur.fetchone()
    conn.close()
    return result

@app.get("/ping")
def ping():
    return {"status": "alive"}

@app.get("/")
def read_root():
    return {"message": "Server is running!"}

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # 1. íŒŒì¼ ì €ì¥
        filepath = f"uploads/{file.filename}"
        with open(filepath, "wb") as f:
            f.write(await file.read())

        # 2. ëª¨ë¸ ì¶”ë¡ 
        raw_results = predict_fabric(filepath)
        print("ğŸ”¥ raw_results:", raw_results)

        # 3. ì˜ˆì¸¡ ê²°ê³¼ ì •ì œ (Top3)
        # ì˜ˆ: raw_results = [{"label": "cotton", "score": 0.87}, {"label": "polyester", "score": 0.09}, ...]
        top3 = sorted(raw_results, key=lambda x: x.get("score", 0), reverse=True)[:3]
        predictions = [
            {"label": x["label"], "score": round(float(x["score"]), 4)} for x in top3
        ]

        # 4. Top1ìœ¼ë¡œ DB ì¡°íšŒ
        top_fabric = top3[0]["label"]
        info = get_fabric_info(top_fabric)

        # 5. ê²°ê³¼ ìƒì„±
        response = {
            "filename": file.filename,
            "predictions": predictions,
            "predicted_fabric": top_fabric,
        }

        if info:
            response.update({
                "ko_name": info[1],
                "wash_method": info[2],
                "dry_method": info[3],
                "special_note": info[4]
            })
        else:
            response["error"] = "DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return response

    except Exception as e:
        print("âŒ ì„œë²„ ì˜¤ë¥˜:", e)
        return {"predictions": [], "error": f"ì„œë²„ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {str(e)}"}

@app.get("/fabric_info/{fabric_name}")
def fabric_info(fabric_name: str):
    info = get_fabric_info(fabric_name)
    if not info:
        raise HTTPException(status_code=404, detail="Fabric not found")
    return {
        "fabric": info[0],
        "ko_name": info[1],
        "wash_method": info[2],
        "dry_method": info[3],
        "special_note": info[4]
    }

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)
    
"""
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
import asyncio
import sqlite3
import uvicorn
import os
import json
import uuid
from model_loader import predict_fabric  # AI ì˜ˆì¸¡ í•¨ìˆ˜

app = FastAPI()
os.makedirs("uploads", exist_ok=True)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (Wix/ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
    allow_methods=["*"],
    allow_headers=["*"],
)

# DB ê²½ë¡œ
DB_PATH = "DB/fabrics.db"

# DBì—ì„œ ì„¸íƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def get_fabric_info(fabric_name):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        """
SELECT fabric, ko_name, wash_method, dry_method, special_note
FROM fabric_care
WHERE LOWER(fabric) = LOWER(?)
""",
        (fabric_name,),
    )
    result = cur.fetchone()
    conn.close()
    return result

@app.get("/ping")
def ping():
    return {"status": "alive"}

@app.get("/")
def read_root():
    return {"message": "Server is running!"}

status_store = {}

@app.post("/predict_stream")
async def predict_stream(file: UploadFile = File(...)):

    # ì‘ì—… ID ìƒì„±
    task_id = str(uuid.uuid4())
    status_store[task_id] = "ì‹œì‘ ëŒ€ê¸° ì¤‘..."

    async def event_generator():
        # 1. íŒŒì¼ ì €ì¥
        status_store[task_id] = "ì´ë¯¸ì§€ ì €ì¥ ì¤‘..."
        yield f"data: {status_store[task_id]}\n\n"
        await asyncio.sleep(0.3)

        file_path = f"uploads/{task_id}_{file.filename}"
        with open(file_path, "wb") as f:
            f.write(await file.read())

        # 2. ì „ì²˜ë¦¬
        status_store[task_id] = "ì „ì²˜ë¦¬ ì¤‘..."
        yield f"data: {status_store[task_id]}\n\n"
        await asyncio.sleep(0.3)

        # 3. íŠ¹ì§• ì¶”ì¶œ
        status_store[task_id] = "íŠ¹ì§• ì¶”ì¶œ ì¤‘..."
        yield f"data: {status_store[task_id]}\n\n"
        await asyncio.sleep(0.3)

        # 4. ì˜ˆì¸¡ ì‹¤í–‰
        status_store[task_id] = "ì˜ˆì¸¡ ì¤‘..."
        yield f"data: {status_store[task_id]}\n\n"
        await asyncio.sleep(0.3)

        # 5. ì‹¤ì œ ì˜ˆì¸¡
        fabric, conf = predict_fabric(file_path)

        # ì˜ˆì¸¡ê°’ ì €ì¥
        status_store[task_id] = {
            "fabric_name": fabric,
            "confidence": conf
        }

        yield f"data: DONE:{task_id}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")
    
@app.get("/predict_result/{task_id}")
async def predict_result(task_id: str):
    if task_id not in status_store:
        return JSONResponse({"error": "invalid task id"}, status_code=404)
    
    result = status_store[task_id]
    if isinstance(result, dict):
        return JSONResponse(result)
    else:
        return JSONResponse({"status": result})
"""

"""
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    async def event_stream():
        try:
            # 1. ì„œë²„ ì—°ê²°
            yield "data: ì„œë²„ ì—°ê²° ì¤‘...\n\n"
            await asyncio.sleep(0.2)

            # 2. íŒŒì¼ ì €ì¥
            yield "data: íŒŒì¼ ì €ì¥ ì¤‘...\n\n"
            data = await file.read()
            filepath = f"uploads/{file.filename}"
            with open(filepath, "wb") as f:
                f.write(data)
            await asyncio.sleep(0.2)

            # 3. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹œì‘
            yield "data: ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...\n\n"
            await asyncio.sleep(0.2)

            # 4. ëª¨ë¸ ì˜ˆì¸¡ ì‹œì‘
            yield "data: ì˜ˆì¸¡ ê³„ì‚° ì¤‘...\n\n"
            raw_results = predict_fabric(filepath)   # ì‹¤ì œ ëª¨ë¸ í˜¸ì¶œ
            await asyncio.sleep(0.2)

            # 5. Top3 ì •ë¦¬
            yield "data: ì˜ˆì¸¡ ê²°ê³¼ ì •ë¦¬ ì¤‘...\n\n"
            top3_list = []
            for item in raw_results[:3]:
                if isinstance(item, (list, tuple)) and len(item) >= 2:
                    top3_list.append({"label": item[0], "probability": item[1]})
                else:
                    top3_list.append({"label": str(item), "probability": None})

            top_fabric = top3_list[0]["label"]

            # 6. DB ì¡°íšŒ
            yield "data: ì¬ì§ˆ ì •ë³´ ì¡°íšŒ ì¤‘...\n\n"
            info = get_fabric_info(top_fabric)
            await asyncio.sleep(0.2)

            # 7. ìµœì¢… JSON ìƒì„±
            if info:
                result = {
                    "filename": file.filename,
                    "top3_predictions": top3_list,
                    "predicted_fabric": top_fabric,
                    "ko_name": info[1],
                    "wash_method": info[2],
                    "dry_method": info[3],
                    "special_note": info[4]
                }
            else:
                result = {
                    "filename": file.filename,
                    "top3_predictions": top3_list,
                    "predicted_fabric": top_fabric,
                    "error": "DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }

            # 8. JSONì„ ë§ˆì§€ë§‰ SSEë¡œ ë³´ë‚´ê¸°
            yield f"data: [RESULT]{json.dumps(result, ensure_ascii=False)}\n\n"

        except Exception as e:
            yield f"data: [ERROR]{str(e)}\n\n"

        yield "data: ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ\n\n"

    return StreamingResponse(event_stream(), media_type="text/event-stream")
"""

"""
@app.get("/fabric_info/{fabric_name}")
def fabric_info(fabric_name: str):
    info = get_fabric_info(fabric_name)
    if not info:
        raise HTTPException(status_code=404, detail="Fabric not found")
    return {
        "fabric": info[0],
        "ko_name": info[1],
        "wash_method": info[2],
        "dry_method": info[3],
        "special_note": info[4]
    }

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)
"""





