
"""
from fastapi import FastAPI, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from tensorflow.keras.models import load_model
from PIL import Image
import numpy as np
import io
import os

app = FastAPI()

# CORS í—ˆìš©
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ëª¨ë¸ ê²½ë¡œ (GitHubì—ì„œ ì´ë¯¸ í¬í•¨ì‹œí‚¨ ëª¨ë¸)
MODEL_PATH = "final_model.keras"  # GitHubì—ì„œ í”„ë¡œì íŠ¸ì— ì˜¬ë¦° ê²½ë¡œ

# ëª¨ë¸ ë¡œë“œ
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"{MODEL_PATH} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. GitHubì—ì„œ ëª¨ë¸ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

model = load_model(MODEL_PATH)

# í´ë˜ìŠ¤ ì´ë¦„ (ëŒ€ë¬¸ì)
CLASS_NAMES = [
    "ACRYLIC", "DENIM", "COTTON", "FUR", "LINEN",
    "NYLON", "POLYESTER", "PUFFER", "RAYON",
    "SLIK", "SPANDEX", "VELVET", "WOOL"
]

@app.get("/")
def root():
    return {"message": "ë°±ì—”ë“œ ì—°ê²° í™•ì¸ ì™„ë£Œ! ğŸ‰"}

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    contents = await file.read()
    img = Image.open(io.BytesIO(contents)).convert("RGB")
    img = img.resize((224, 224))
    x = np.array(img) / 255.0
    x = np.expand_dims(x, axis=0)

    preds = model.predict(x)
    class_index = int(np.argmax(preds))
    label = CLASS_NAMES[class_index]
    confidence = float(preds[0][class_index])

    return {
        "filename": file.filename,
        "size_bytes": len(contents),
        "label": label,
        "class_index": class_index,
        "confidence": confidence
    }

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
    
### formdata í˜•ì‹
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import os
from model_loader import predict_fabric

app = FastAPI() #fastAPI ì„œë²„ ê°ì²´ ìƒì„±
os.makedirs("uploads", exist_ok=True)

# CORS ì„¤ì • 
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš©
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš©
    allow_headers=["*"],  # ëª¨ë“  í—¤ë” í—ˆìš©
)

@app.get("/")
def read_root():
    return {"message": "Server is running!"}

# /predict ì—”ë“œí¬ì¸íŠ¸
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    filepath = f"uploads/{file.filename}"
    with open(filepath, "wb") as f:
        f.write(await file.read())

    # ëª¨ë¸ ì¶”ë¡ 
    results = predict_fabric(filepath)

    return {
        "filename": file.filename,
        "predictions": results   # ì „ì²´ Top-3 ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    }

#ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)

#formdata
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import os
import requests
from model_loader import predict_fabric  # filepath ì…ë ¥ ë°›ëŠ” í•¨ìˆ˜

app = FastAPI()
os.makedirs("uploads", exist_ok=True)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def read_root():
    return {"message": "Server is running!"}

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # 1. ì„œë²„ì— íŒŒì¼ ì €ì¥
        filepath = f"uploads/{file.filename}"
        with open(filepath, "wb") as f:
            f.write(await file.read())

        # 2. ëª¨ë¸ ì¶”ë¡ 
        raw_results = predict_fabric(filepath) 
        results = []

        for item in raw_results[:3]:  # Top-3
            label = item[0] if isinstance(item, (list, tuple)) and len(item) > 0 else str(item)
            results.append({"label": str(label)})

        return {
            "filename": file.filename,
            "predictions": results
        }
        
    except requests.exceptions.RequestException as e:
        # ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
        return {"predictions": [], "error": f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}"}
    except Exception as e:
        # PIL ì—´ê¸°, ëª¨ë¸ ì¶”ë¡  ë“± ê¸°íƒ€ ì—ëŸ¬
        return {"predictions": [], "error": f"ì„œë²„ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {str(e)}"}

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000)) 
    uvicorn.run(app, host="0.0.0.0", port=port)
  """  
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import sqlite3
import uvicorn
import os
from model_loader import predict_fabric  # AI ì˜ˆì¸¡ í•¨ìˆ˜

app = FastAPI()
os.makedirs("uploads", exist_ok=True)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],   # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (Wix/ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
    allow_methods=["*"],
    allow_headers=["*"],
)

# DB ê²½ë¡œ
DB_PATH = "DB/fabrics.db"

# DBì—ì„œ ì„¸íƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def get_fabric_info(fabric_name):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        "SELECT fabric, ko_name, wash_method, dry_method, special_note FROM fabric_care WHERE fabric = ?",
        (fabric_name,),
    )
    result = cur.fetchone()
    conn.close()
    return result


# ë£¨íŠ¸ í™•ì¸ìš© ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
def read_root():
    return {"message": "Server is running!"}

# /predict ì—”ë“œí¬ì¸íŠ¸
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # 1. íŒŒì¼ ì €ì¥
        filepath = f"uploads/{file.filename}"
        with open(filepath, "wb") as f:
            f.write(await file.read())

        # 2. ëª¨ë¸ ì¶”ë¡  (ë¼ë²¨ í¬í•¨)
        raw_results = predict_fabric(filepath) #?
        
        # 3. Top-3 ì¶”ì¶œ
        top3 = raw_results[:3]
        top3_list = [{"label": item[0], "probability": item[1]} for item in top3]

        # 4. ìƒìœ„ 1ê°œ DB ì¡°íšŒ
        top_fabric = top3[0][0]
        info = get_fabric_info(top_fabric)

        # 5. JSON ë°˜í™˜
        if info:
            response = {
                "filename": file.filename,
                "top3_predictions": top3_list,
                "predicted_fabric": top_fabric,
                "ko_name": info[1],
                "wash_method": info[2],
                "dry_method": info[3],
                "special_note": info[4]
            }
        else:
            response = {
                "filename": file.filename,
                "top3_predictions": top3_list,
                "predicted_fabric": top_fabric,
                "error": "DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

        return response

    except Exception as e:
        return {"predictions": [], "error": f"ì„œë²„ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {str(e)}"}

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)

"""
# /predict : ì´ë¯¸ì§€ ì—…ë¡œë“œ â†’ AI ì˜ˆì¸¡ â†’ DB ì¡°íšŒ
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    # 1. ì—…ë¡œë“œ íŒŒì¼ ì €ì¥
    filepath = f"uploads/{file.filename}"
    with open(filepath, "wb") as f:
        f.write(await file.read())

    # 2. AI ëª¨ë¸ ì˜ˆì¸¡
    results = predict_fabric(filepath)  ##?

    # 3. ê²°ê³¼ í˜•ì‹ í™•ì¸ ë° ë³€í™˜
    if isinstance(results, list):
        # í´ë˜ìŠ¤ ìˆœì„œì™€ ê²°ê³¼ í™•ë¥ ì„ ì§ì§€ì–´ì„œ dictë¡œ ë³€í™˜
        fabric_labels = ["acrylic", "cotton", "denim", "fur", "linen", "nylon", "polyester", "silk", "wool"]
        if isinstance(results[0], list):  # 2ì°¨ì› ë°°ì—´ì¸ ê²½ìš°
            results = results[0]
        results = dict(zip(fabric_labels, results))

    # 4. ê°€ì¥ í™•ë¥  ë†’ì€ ì¬ì§ˆëª… ì„ íƒ
    predicted_fabric = max(results, key=results.get)
    
    """
    # 3. ê°€ì¥ í™•ë¥  ë†’ì€ ì¬ì§ˆëª… ì„ íƒ
    predicted_fabric = max(results, key=results.get)

    # 4. DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    info = get_fabric_info(predicted_fabric)
   """

    # 5. ë°˜í™˜ê°’ êµ¬ì„±
    if info:
        response = {
            "filename": file.filename,
            "predicted_fabric": predicted_fabric,
            "ko_name": info[1],
            "wash_method": info[2],
            "dry_method": info[3],
            "special_note": info[4],
            "predictions": results  # ì „ì²´ ì˜ˆì¸¡ í™•ë¥  í¬í•¨
        }
    else:
        response = {
            "filename": file.filename,
            "predicted_fabric": predicted_fabric,
            "error": "DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "predictions": results
        }

    return response

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)
"""







