"""
#formdata
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import os
import requests
from model_loader import predict_fabric  # filepath ì…ë ¥ ë°›ëŠ” í•¨ìˆ˜

app = FastAPI()
os.makedirs("uploads", exist_ok=True)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def read_root():
    return {"message": "Server is running!"}

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # 1. ì„œë²„ì— íŒŒì¼ ì €ì¥
        filepath = f"uploads/{file.filename}"
        with open(filepath, "wb") as f:
            f.write(await file.read())

        # 2. ëª¨ë¸ ì¶”ë¡ 
        raw_results = predict_fabric(filepath) 
        results = []

        for item in raw_results[:3]:  # Top-3
            label = item[0] if isinstance(item, (list, tuple)) and len(item) > 0 else str(item)
            results.append({"label": str(label)})

        return {
            "filename": file.filename,
            "predictions": results
        }
        
    except requests.exceptions.RequestException as e:
        # ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
        return {"predictions": [], "error": f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}"}
    except Exception as e:
        # PIL ì—´ê¸°, ëª¨ë¸ ì¶”ë¡  ë“± ê¸°íƒ€ ì—ëŸ¬
        return {"predictions": [], "error": f"ì„œë²„ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {str(e)}"}

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000)) 
    uvicorn.run(app, host="0.0.0.0", port=port)
     
#DB ì¶”ê°€
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import sqlite3
import uvicorn
import os
from model_loader import predict_fabric  # AI ì˜ˆì¸¡ í•¨ìˆ˜

app = FastAPI()
os.makedirs("uploads", exist_ok=True)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (Wix/ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
    allow_methods=["*"],
    allow_headers=["*"],
)

# DB ê²½ë¡œ
DB_PATH = "DB/fabrics.db"

# DBì—ì„œ ì„¸íƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def get_fabric_info(fabric_name):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        "SELECT fabric, ko_name, wash_method, dry_method, special_note FROM fabric_care WHERE LOWER(fabric) = LOWER(?)",
        (fabric_name,),
    )
    result = cur.fetchone()
    conn.close()
    return result

# ë£¨íŠ¸ í™•ì¸ìš©
@app.get("/")
def read_root():
    return {"message": "Server is running!"}

# /predict ì—”ë“œí¬ì¸íŠ¸
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # 1. íŒŒì¼ ì €ì¥
        filepath = f"uploads/{file.filename}"
        with open(filepath, "wb") as f:
            f.write(await file.read())

        # 2. ëª¨ë¸ ì¶”ë¡  (ë¼ë²¨ + í™•ë¥  í¬í•¨)
        raw_results = predict_fabric(filepath)
        print("ğŸ”¥ raw_results:", raw_results)
        
        # 3. Top-3 ì •ë ¬ (score ë†’ì€ ìˆœ)
        top3 = sorted(raw_results, key=lambda x: x["score"], reverse=True)[:3]
        top3_list = [{"label": x["label"], "score": float(x["score"])} for x in top3]

        # 4. Top-1ë¡œ DB ì¡°íšŒ
        top_fabric = top3[0]["label"]
        info = get_fabric_info(top_fabric)

        # 5. ê²°ê³¼ ìƒì„±
        response = {
            "filename": file.filename,
            "predictions": top3_list,  # ğŸ‘ˆ í”„ë¡ íŠ¸ì—ì„œ ë°›ëŠ” key ì´ë¦„ í†µì¼
            "predicted_fabric": top_fabric
        }

        if info:
            response.update({
                "ko_name": info[1],
                "wash_method": info[2],
                "dry_method": info[3],
                "special_note": info[4]
            })
        else:
            response["error"] = "DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return response
        
    except Exception as e:
        print("âŒ ì„œë²„ ì˜¤ë¥˜:", e)
        return {"predictions": [], "error": f"ì„œë²„ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {str(e)}"}
        
        ###
        # 3. Top-3 ì¶”ì¶œ
        top3 = raw_results[:3]
        top3_list = [{"label": item["label"], "probability": item["score"]} for item in top3]

        # 4. ìƒìœ„ 1ê°œ DB ì¡°íšŒ (ë¼ë²¨ ì´ë¦„ë§Œ ì „ë‹¬)
        top_fabric = top3[0]["label"]
        info = get_fabric_info(top_fabric)

        # 5. JSON ë°˜í™˜
        if info:
            response = {
                "filename": file.filename,
                "top3_predictions": top3_list,
                "predicted_fabric": top_fabric,
                "ko_name": info[1],
                "wash_method": info[2],
                "dry_method": info[3],
                "special_note": info[4]
            }
        else:
            response = {
                "filename": file.filename,
                "top3_predictions": top3_list,
                "predicted_fabric": top_fabric,
                "error": "DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

        return response
        ###

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)


##DB +
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import sqlite3
import uvicorn
import os
from model_loader import predict_fabric  # AI ì˜ˆì¸¡ í•¨ìˆ˜


app = FastAPI()
os.makedirs("uploads", exist_ok=True)


# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (Wix/ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
    allow_methods=["*"],
    allow_headers=["*"],
)

# DB ê²½ë¡œ
DB_PATH = "DB/fabrics.db"

# DBì—ì„œ ì„¸íƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def get_fabric_info(fabric_name):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        """
        SELECT fabric, ko_name, wash_method, dry_method, special_note
        FROM fabric_care
        WHERE LOWER(fabric) = LOWER(?)
        """,
        (fabric_name,),
    )
    result = cur.fetchone()
    conn.close()
    return result

@app.get("/ping")
def ping():
    return {"status": "alive"}

@app.get("/")
def read_root():
    return {"message": "Server is running!"}

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # 1. íŒŒì¼ ì €ì¥
        filepath = f"uploads/{file.filename}"
        with open(filepath, "wb") as f:
            f.write(await file.read())

        # 2. ëª¨ë¸ ì¶”ë¡ 
        raw_results = predict_fabric(filepath)
        print("ğŸ”¥ raw_results:", raw_results)

        # 3. ì˜ˆì¸¡ ê²°ê³¼ ì •ì œ (Top3)
        # ì˜ˆ: raw_results = [{"label": "cotton", "score": 0.87}, {"label": "polyester", "score": 0.09}, ...]
        top3 = sorted(raw_results, key=lambda x: x.get("score", 0), reverse=True)[:3]
        predictions = [
            {"label": x["label"], "score": round(float(x["score"]), 4)} for x in top3
        ]

        # 4. Top1ìœ¼ë¡œ DB ì¡°íšŒ
        top_fabric = top3[0]["label"]
        info = get_fabric_info(top_fabric)

        # 5. ê²°ê³¼ ìƒì„±
        response = {
            "filename": file.filename,
            "predictions": predictions,
            "predicted_fabric": top_fabric,
        }

        if info:
            response.update({
                "ko_name": info[1],
                "wash_method": info[2],
                "dry_method": info[3],
                "special_note": info[4]
            })
        else:
            response["error"] = "DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return response

    except Exception as e:
        print("âŒ ì„œë²„ ì˜¤ë¥˜:", e)
        return {"predictions": [], "error": f"ì„œë²„ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {str(e)}"}

@app.get("/fabric_info/{fabric_name}")
def fabric_info(fabric_name: str):
    info = get_fabric_info(fabric_name)
    if not info:
        raise HTTPException(status_code=404, detail="Fabric not found")
    return {
        "fabric": info[0],
        "ko_name": info[1],
        "wash_method": info[2],
        "dry_method": info[3],
        "special_note": info[4]
    }
    
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)

"""

from fastapi import FastAPI, UploadFile, File
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
import sqlite3
import asyncio
import os
import json
import uvicorn
from model_loader import predict_fabric  # AI ì˜ˆì¸¡ í•¨ìˆ˜

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()
os.makedirs("uploads", exist_ok=True)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],   # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (ì „ì‹œìš©)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# DB ê²½ë¡œ ë° ì¡°íšŒ í•¨ìˆ˜
DB_PATH = "DB/fabrics.db"

def get_fabric_info(fabric_name: str):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        """
        SELECT fabric, ko_name, wash_method, dry_method, special_note
        FROM fabric_care
        WHERE LOWER(fabric) = LOWER(?)
        """,
        (fabric_name,),
    )
    result = cur.fetchone()
    conn.close()
    return result


@app.get("/ping")
def ping():
    return {"status": "alive"}


@app.get("/")
def root():
    return {"message": "AI ì„¬ìœ  ë¶„ì„ ì„œë²„ ê°€ë™ ì¤‘"}

@app.post("/analyze_stream")
async def analyze_stream(file: UploadFile = File(...)):
    async def event_generator():
        try:
            steps = [
                "ì„œë²„ ì—°ê²° ì¤‘...",
                "ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...",
                "ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...",
                "ì˜ˆì¸¡ ê³„ì‚° ì¤‘..."
            ]
            for step in steps:
                yield f"data: {step}\n\n"
                await asyncio.sleep(0.8)

            # íŒŒì¼ì„ í•œ ë²ˆë§Œ ì½ì–´ ì €ì¥ (ì¤‘ë³µ ì½ê¸° ë°©ì§€)
            data = await file.read()
            filepath = f"uploads/{file.filename}"
            with open(filepath, "wb") as f:
                f.write(data)

            yield f"data: ê²°ê³¼ ë¶„ì„ ì¤‘...\n\n"
            await asyncio.sleep(0.5)

            raw_results = predict_fabric(filepath)
            top3_list = []
            for item in raw_results[:3]:
                if isinstance(item, (list, tuple)) and len(item) >= 2:
                    top3_list.append({"label": item[0], "probability": item[1]})
                else:
                    top3_list.append({"label": str(item), "probability": None})

            top_fabric = top3_list[0]["label"] if top3_list else None
            info = get_fabric_info(top_fabric) if top_fabric else None

            if info:
                result = {
                    "predicted_fabric": top_fabric,
                    "ko_name": info[1],
                    "wash_method": info[2],
                    "dry_method": info[3],
                    "special_note": info[4],
                    "top3_predictions": top3_list,
                }
            else:
                result = {
                    "predicted_fabric": top_fabric,
                    "top3_predictions": top3_list,
                    "error": "DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }

            # í”„ë¡ íŠ¸ê°€ ê°ì§€í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì „ì†¡
            yield f"data: [RESULT]{json.dumps(result, ensure_ascii=False)}\n\n"

        except Exception as e:
            yield f"data: [ERROR]{str(e)}\n\n"

        yield f"data: ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ âœ…\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")

# âœ… ì¼ë°˜ ì˜ˆì¸¡ (ë¹„ë™ê¸° ì•„ë‹˜ â€” ë‹¨ë… ê²°ê³¼ìš©)
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        filepath = f"uploads/{file.filename}"
        with open(filepath, "wb") as f:
            f.write(await file.read())

        raw_results = predict_fabric(filepath)

        if not raw_results or not isinstance(raw_results, list):
            raise ValueError("ëª¨ë¸ ë°˜í™˜ê°’ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        top3_list = []
        for item in raw_results[:3]:
            if isinstance(item, (list, tuple)) and len(item) >= 2:
                top3_list.append({"label": item[0], "probability": item[1]})
            else:
                top3_list.append({"label": str(item), "probability": None})

        top_fabric = top3_list[0]["label"]
        info = get_fabric_info(top_fabric)

        if info:
            response = {
                "filename": file.filename,
                "top3_predictions": top3_list,
                "predicted_fabric": top_fabric,
                "ko_name": info[1],
                "wash_method": info[2],
                "dry_method": info[3],
                "special_note": info[4]
            }
        else:
            response = {
                "filename": file.filename,
                "top3_predictions": top3_list,
                "predicted_fabric": top_fabric,
                "error": "DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

        return response

    except Exception as e:
        return {"predictions": [], "error": f"ì„œë²„ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {str(e)}"}

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)






