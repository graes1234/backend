"""
#ìŠ¤íŠ¸ë¦¼ ê¸°ì¤€
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
import uvicorn
import os
import sqlite3
from fastapi.responses import FileResponse, StreamingResponse
import json
from model_loader import predict_fabric
import asyncio
import time

app = FastAPI()
os.makedirs("uploads", exist_ok=True)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (Wix/ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
    allow_methods=["*"],
    allow_headers=["*"],
)

# DB ê²½ë¡œ
DB_PATH = "DB/fabrics.db"

# DBì—ì„œ ì„¸íƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def get_fabric_info(fabric_name):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        "SELECT fabric, ko_name, wash_method, dry_method, special_note FROM fabric_care WHERE LOWER(fabric) = LOWER(?)",
        (fabric_name,),
    )
    result = cur.fetchone()
    conn.close()
    return result

@app.get("/ping")
def ping():
    return {"status": "alive"}

@app.get("/")
def read_root():
    return {"message": "Server is running!"}

@app.post("/predict_stream")
async def predict_stream(file: UploadFile = File(...)):

    # íŒŒì¼ ì €ì¥
    file_bytes = await file.read()
    filepath = f"uploads/{file.filename}"
    with open(filepath, "wb") as f:
        f.write(file_bytes)

    async def event_generator():
        # 1) ë‹¨ê³„ë³„ ì§„í–‰ìƒíƒœ
        steps = [
            "ğŸŒğŸ”ŒğŸ’«ì„œë²„ ì—°ê²° ì¤‘...",
            "ğŸ§ ğŸ“¦â³ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...",
            "ğŸ”âš¡ğŸ“Šê²°ê³¼ ì˜ˆì¸¡ ì¤‘..."
        ]

        for step in steps:
            yield json.dumps({"status": step}) + "\n"
            await asyncio.sleep(0.3)

        # 2) ì‹¤ì œ ëª¨ë¸ ì¶”ë¡ 
        raw_results = predict_fabric(filepath)
        top3 = sorted(raw_results, key=lambda x: x.get("score", 0), reverse=True)[:3]
        predictions = [{"label": x["label"], "score": round(float(x["score"]), 4)} for x in top3]

        top_fabric = top3[0]["label"]
        info = get_fabric_info(top_fabric)

        response = {
            "filename": file.filename,
            "predictions": predictions,
            "predicted_fabric": top_fabric,
        }

        if info:
            response.update({
                "ko_name": info[1],
                "wash_method": info[2],
                "dry_method": info[3],
                "special_note": info[4],
            })

        # 3) ìµœì¢… JSON í•œ ì¤„
        yield json.dumps({"status": "âœ…ğŸ‰âœ¨ì˜ˆì¸¡ ì™„ë£Œ!", "result": response}) + "\n"

    return StreamingResponse(event_generator(), media_type="text/plain")

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # 1. íŒŒì¼ ì €ì¥
        filepath = f"uploads/{file.filename}"
        with open(filepath, "wb") as f:
            f.write(await file.read())

        # 2. ëª¨ë¸ ì¶”ë¡ 
        raw_results = predict_fabric(filepath)
        print("ğŸ”¥ raw_results:", raw_results)

        # 3. ì˜ˆì¸¡ ê²°ê³¼ ì •ì œ (Top3)
        # ì˜ˆ: raw_results = [{"label": "cotton", "score": 0.87}, {"label": "polyester", "score": 0.09}, ...]
        top3 = sorted(raw_results, key=lambda x: x.get("score", 0), reverse=True)[:3]
        predictions = [
            {"label": x["label"], "score": round(float(x["score"]), 4)} for x in top3
        ]

        # 4. Top1ìœ¼ë¡œ DB ì¡°íšŒ
        top_fabric = top3[0]["label"]
        info = get_fabric_info(top_fabric)

        # 5. ê²°ê³¼ ìƒì„±
        response = {
            "filename": file.filename,
            "predictions": predictions,
            "predicted_fabric": top_fabric,
        }

        if info:
            response.update({
                "ko_name": info[1],
                "wash_method": info[2],
                "dry_method": info[3],
                "special_note": info[4]
            })
        else:
            response["error"] = "DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return response

    except Exception as e:
        print("âŒ ì„œë²„ ì˜¤ë¥˜:", e)
        return {"predictions": [], "error": f"ì„œë²„ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {str(e)}"}

@app.get("/fabric_info/{fabric_name}")
def fabric_info(fabric_name: str):
    info = get_fabric_info(fabric_name)
    if not info:
        raise HTTPException(status_code=404, detail="Fabric not found")
    return {
        "fabric": info[0],
        "ko_name": info[1],
        "wash_method": info[2],
        "dry_method": info[3],
        "special_note": info[4]
    }


# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)
"""

from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
import os
import sqlite3
from fastapi.responses import FileResponse, StreamingResponse
import json
from model_loader import predict_fabric, load_and_preprocess, run_inference, class_names
import asyncio
import time
from fastapi.staticfiles import StaticFiles

app = FastAPI()
os.makedirs("uploads", exist_ok=True)

model_ready = False

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],   # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (Wix/ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# DB ê²½ë¡œ
DB_PATH = "DB/fabrics.db"

# DBì—ì„œ ì„¸íƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
def get_fabric_info(fabric_name):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute(
        "SELECT fabric, ko_name, wash_method, dry_method, special_note FROM fabric_care WHERE LOWER(fabric) = LOWER(?)",
        (fabric_name,),
    )
    result = cur.fetchone()
    conn.close()
    return result

@app.get("/ping")
def ping():
    return {"status": "alive"}

@app.get("/")
async def read_root():
    index_path = os.path.join("../front", "index.html")
    if os.path.exists(index_path):
        return FileResponse(index_path)
    return {"message": "Server is running!"}

@app.on_event("startup")
async def startup_event():
    global model_ready
    try:
        _ = model.predict(np.zeros((1, 224, 224, 3)))  # ë”ë¯¸ ì˜ˆì¸¡
        model_ready = True
    except:
        model_ready = False

@app.get("/server_ready")
async def server_ready():
    return {"ready": model_ready}

@app.post("/predict_stream")
async def predict_stream(file: UploadFile = File(...)):
    async def event_generator(): #event_stream
        # 1. ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥
        yield json.dumps({"status": "ğŸ“â³ğŸ’¾ ì´ë¯¸ì§€ ì €ì¥ ì¤‘..."}) + "\n"
        file_bytes = await file.read()
        filepath = f"uploads/{file.filename}"
        with open(filepath, "wb") as f:
            f.write(file_bytes)
        await asyncio.sleep(0.1)

        # 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        yield json.dumps({"status": "ğŸ§¼ğŸ§ªğŸ”§ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘..."}) + "\n"
        x = load_and_preprocess(filepath)
        await asyncio.sleep(0.1)

        # 3. ì˜ˆì¸¡ ì‹œì‘
        yield json.dumps({"status": "ğŸ”âš¡ğŸ“Šê²°ê³¼ ì˜ˆì¸¡ ì¤‘..."}) + "\n"

        #  ì‹¤ì œ ëª¨ë¸ ì˜ˆì¸¡ (ê±¸ë¦¬ëŠ” ì‹œê°„ ê·¸ëŒ€ë¡œ ìŠ¤íŠ¸ë¦¬ë°ì— ë°˜ì˜ë¨)
        preds = run_inference(x)

        # ê²°ê³¼ ìƒìœ„ 3ê°œ ì •ë ¬
        top3 = [
            {"label": class_names[i], "score": float(preds[i])}
            for i in range(len(class_names))
        ]
        top3 = sorted(top3, key=lambda x: x["score"], reverse=True)[:3]

        top_fabric = top3[0]["label"]
        info = get_fabric_info(top_fabric)

        result = {
            "filename": file.filename,
            "predictions": top3,
            "predicted_fabric": top_fabric,
        }

        if info:
            result.update({
                "ko_name": info[1],
                "wash_method": info[2],
                "dry_method": info[3],
                "special_note": info[4]
            })

        yield json.dumps({
            "status": "âœ…ğŸ‰âœ¨ ì˜ˆì¸¡ ì™„ë£Œ!",
            "result": result
        }) + "\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/plain",
        headers={"Cache-Control": "no-cache"}
    )

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    try:
        # 1. íŒŒì¼ ì €ì¥
        filepath = f"uploads/{file.filename}"
        with open(filepath, "wb") as f:
            f.write(await file.read())

        # 2. ëª¨ë¸ ì¶”ë¡ 
        raw_results = predict_fabric(filepath)
        print("ğŸ”¥ raw_results:", raw_results)

        # 3. ì˜ˆì¸¡ ê²°ê³¼ ì •ì œ (Top3)
        # ì˜ˆ: raw_results = [{"label": "cotton", "score": 0.87}, {"label": "polyester", "score": 0.09}, ...]
        top3 = sorted(raw_results, key=lambda x: x.get("score", 0), reverse=True)[:3]
        predictions = [
            {"label": x["label"], "score": round(float(x["score"]), 4)} for x in top3
        ]

        # 4. Top1ìœ¼ë¡œ DB ì¡°íšŒ
        top_fabric = top3[0]["label"]
        info = get_fabric_info(top_fabric)

        # 5. ê²°ê³¼ ìƒì„±
        response = {
            "filename": file.filename,
            "predictions": predictions,
            "predicted_fabric": top_fabric,
        }

        if info:
            response.update({
                "ko_name": info[1],
                "wash_method": info[2],
                "dry_method": info[3],
                "special_note": info[4]
            })
        else:
            response["error"] = "DBì—ì„œ í•´ë‹¹ ì¬ì§ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return response

    except Exception as e:
        print("âŒ ì„œë²„ ì˜¤ë¥˜:", e)
        return {"predictions": [], "error": f"ì„œë²„ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {str(e)}"}

@app.get("/fabric_info/{fabric_name}")
def fabric_info(fabric_name: str):
    info = get_fabric_info(fabric_name)
    if not info:
        raise HTTPException(status_code=404, detail="Fabric not found")
    return {
        "fabric": info[0],
        "ko_name": info[1],
        "wash_method": info[2],
        "dry_method": info[3],
        "special_note": info[4]
    }

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)



